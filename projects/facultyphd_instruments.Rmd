
```{r echo=FALSE, results='asis'}
project("facultyphd", 3)
```

As the final assignment of EDPY 583 Survey Research, I designed a survey-based research proposal called *Faculty Perceptions of the Conference Attendance of Recently-Graduated PhD Job Applicants: A Survey*. The purpose of this survey instrument was to understand the value faculty place on conference travel when hiring newly-graduated PhD students. The survey underwent a lengthy in-class development process that entailed background research, construct development, item development, pretesting, and student review.

I received very positive comments on the survey and research proposal and was quite excited to develop a final version of the survey, which I thought would dovetail very nicely with my *PhD Student Conferences and Employability* survey/research. At the end of the semester, I obtained IRB approval to begin cognitive interviews to improve the survey before more in-depth pilot testing.

However, I launched my *PhD Student* survey first and had a rude awakening that carried over to this project. As I have detailed elsewhere, my *PhD Student* survey had a dismal response rate, even after spending $400 in recruitment (via Twitter, HigherEdJobs.com) in an effort to attract more respondents. My reaction to the poor response rate for that survey was to implement an alternative plan in which I emailed around 1,500 department heads from around the country. I got most of my responses through this method, but still had a low response rate (final n was 120 whereas I planned to recruit 300 in order to have adequate statistical power). 

After my experiences with the *PhD Student* survey, I decided to cancel this project. There were two main reasons. First, and most obvious, is that the response rate of my previous survey left me disillusioned with survey research. I did not want to deal with the anxiety that comes with dedicating so much effort to a project just to get a sample size so inadequate that the research plans simply do not work out. Second, the target audience of the faculty survey was department heads. I felt I had already used up this sample pool. I did not feel comfortable about contacting the same group of people twice regarding surveys. And, it certainly would have been the same group of people. To contact the department heads, I scoured Google for all publicly available department head lists, as this is much more feasible than selecting institutions individually and then searching around to see whether they have a list available or not (more often, it is not). I went dozens of pages deep in Google to get the most complete list I could. There is no feasible way I could develop an adequately-sized second list that did not match almost exactly. 

If I restarted this project now, there are a few things I would do differently. First, I would narrow my population from all department heads nationwide to a specific region or group of institutions. Perhaps I would make it a case study of only one institution (e.g. UTK). The potential small sample size may wreak havoc on my statistical models though. I would feel more comfortable with a narrower sample of multiple institutions if I were able to offer incentives. However, as a graduate student, I have not found sources of funding that allow incentives. At the time of developing the survey, I was not thinking of data simulation and analytically testing my survey. Were I to do this project again, I think that I would also simulate data and test my survey design to make sure potential results answer my research question and are actually feasible through my proposed methods. 

The experiences I learned from the *PhD Student Conferences* and *Faculty Conference Attitudes* projects have both left me with a negative impression of survey research, which I have mentioned numerous times in previous reflections. This is one reason my dissertation will be focused on a large, publicly-available national data set. It does not make the research any easier, but it does alleviate the anxiety related to data collection - anxiety I do not wish to feel again. Lest I sound like a anti-survey curmudgeon, I do see the value in survey research and have been very happy to work on the *Sustainable Energy Working Group* survey , especially because we have funding for incentives and thus potential for adequate sample sizes. I also recognize that survey research will still be in my future, as I work for an organization that conducts surveys and have looked for jobs at other organizations such as Pew and Gallup.
