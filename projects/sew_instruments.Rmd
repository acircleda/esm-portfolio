
```{r echo=FALSE, results='asis'}
project("sustainable", 3)
```

  In my first reflection on this project, I detailed the development of a survey to assess student attitudes toward sustainable energy at UTK. I did so through a evaluation lens, reflecting on questionnaire development as a function of client relations skills. I also have taken what I have learned from previous projects regarding piloting and testing analysis models and have purposefully applied them to this project.

At the time of writing, the survey is being reviewed by the IRB and will be deployed sometime next month. While waiting for revisions or acceptance, I have gone taken the survey's pilot data and developed a skeleton report, including code for key statistics and visualizations. This has allowed me to think through the data we will be getting, how best to organize it, and how best to visualize it. For example, we have several ranking questions. These questions are more difficult to work with than regular Likert-style questions, especially since not all items need to be ranked, and thus, when calculating overall rank, a weighted ranking score needs to be developed. Working with the pilot data, I have been able to develop a valid scoring method that is also easy to visualize. When the final survey gets distributed and actual results come in, it should be relatively simple to run the code and get the actual results visualized.

In addition, by going through the code, I was able to spot issues with how Qualtrics recoded a series of questions on the survey. We included several bipolar questions on a 7-point scale from -3 to 3. However, Qualtircs coded these in a way I still do not understand, which included 11, 13, and 14. I contacted Qulatrics tech support and we were able to get the question coding correctly. I generated additional test results, just to make sure. In addition, I was able to spot several spelling mistakes through coding and have fixed them in the actual survey.

Finally, we plan to use post-stratification survey weighting, specifically raking, to make sure our results are more representative of the UTK population. In anticipation of this, I have simulated a data set of population estimates (e.g. estimates of the proportion of males/females, different racial proportions, different proportions of students from the various colleges) and applied survey raking techniques to generate survey weights for the pilot data. I have then added coding to make use of weights in the analysis. By doing so, I have been able to make sure the raking process works for my data. I also discovered that pivoting data from wide to long is not possible after a weighted survey design is created and so it is better to pivot data first and then apply a survey design. In fact, it is better to apply the survey design multiple times when complicated analyses are being done. Additionally, by working with simulated and pilot data, I have been able to anticipate that I may need to deal with missing data, which is a bit difficult to do when raking. This is because raking relies on marginal population estimates, and there is typically no missing data at the population level. I have found several resources on how to deal with this. 

All of these pre-data collection activities have been important in helping me ensure our survey makes sense analytically. I have learned from previous experiences that this is crucial to having not only a useful survey but also useful results The sustainable energy survey has been an excellent opportunity to take what I learned from these previous experience and put them into action.
